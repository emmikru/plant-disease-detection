


# -- Basis-Imports --
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# -- Machine Learning / Deep Learning --
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
)
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications import (
    MobileNetV2, ResNet50V2, EfficientNetB0
)

# -- Tools --
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split






import kagglehub

# Download latest version
path = kagglehub.dataset_download("emmarex/plantdisease")

print("Path to dataset files:", path)





import random
from PIL import Image

# Richtiger PlantVillage-Datenordner
dataset_dir = os.path.join(path, "PlantVillage", "PlantVillage")

print("Datensatzordner:", dataset_dir)

# --- Klassenordner laden ---
folders = [
    f for f in os.listdir(dataset_dir)
    if os.path.isdir(os.path.join(dataset_dir, f))
]

print("Anzahl Klassen:", len(folders))
print("Beispeilklassen:", folders[:10])

# --- Bilder pro Klasse zählen ---
class_counts = {}
total_images = 0 

for cls in folders:
    cls_path = os.path.join(dataset_dir, cls)
    images = [
        f for f in os.listdir(cls_path)
        if f.lower().endswith((".jpg", ".jpeg", ".png"))
    ]
    class_counts[cls] = len(images)
    total_images += len(images)

print("\nBilder pro Klasse:")
for cls, count in class_counts.items():
    print(f"{cls}: {count}")

print(f"\nGesamtanzahl aller Bilder im Datensatz: {total_images}")

# --- Beispielbilder anzeigen ---
sample_classes = random.sample(folders, 4)

plt.figure(figsize=(14, 10))
for i, cls in enumerate(sample_classes):
    cls_path = os.path.join(dataset_dir, cls)
    images = [
        f for f in os.listdir(cls_path)
        if f.lower().endswith((".jpg", ".jpeg", ".png"))
    ]
    
    if not images:
        continue  # überspringt leere Ordner, falls vorhanden
    
    img_path = os.path.join(cls_path, random.choice(images))
    img = Image.open(img_path)

    plt.subplot(2, 2, i + 1)  # 2x2 Layout
    plt.imshow(img)
    plt.title(cls, fontsize=12)
    plt.axis("off")

plt.suptitle("Zufällige Beispielbilder aus verschiedenen Klassen", fontsize=16)
plt.tight_layout()
plt.show()






# Dictionary in DataFrame umwandeln
class_df = pd.DataFrame.from_dict(class_counts, orient='index', columns=['count'])
class_df = class_df.sort_values(by='count', ascending=False)

# Plot
plt.figure(figsize=(14, 6))
plt.bar(class_df.index, class_df['count'], color='steelblue')
plt.xticks(rotation=90)
plt.title("Bilder pro Klasse im PlantVillage-Datensatz", fontsize=16)
plt.xlabel("Kategorien / Krankheiten")
plt.ylabel("Anzahl der Bilder")
plt.tight_layout()
plt.show()






image_paths = []
labels = []

# Durchlaufe jede Klasse und sammle Bildpfade
for cls in folders:
    cls_path = os.path.join(dataset_dir, cls)
    
    images = [
        f for f in os.listdir(cls_path)
        if f.lower().endswith((".jpg", ".jpeg", ".png"))
    ]
    
    for img in images:
        image_paths.append(os.path.join(cls_path, img))
        labels.append(cls)

# In DataFrame überführen
df = pd.DataFrame({
    "path": image_paths,
    "label": labels
})

print(len(df))
df.head()






# --- 1. Split: Train + Temp (Val+Test) ---
train_df, temp_df = train_test_split(
    df,
    test_size=0.30,     # 70% Train, 30% Temp
    stratify=df["label"],
    random_state=42
)

# --- 2. Split: Temp -> Validation + Test ---
val_df, test_df = train_test_split(
    temp_df,
    test_size=0.50,     # Hälfte der 30% -> 15% Test, 15% Val
    stratify=temp_df["label"],
    random_state=42
)

# --- Ausgabe der Größen ---
print("Größe der Datensplits:")
print("Training:", len(train_df))
print("Validation:", len(val_df))
print("Test:", len(test_df))

# --- Prüfung: Anzahl Klassen unverändert? ---
print("\nAnzahl Klassen:")
print("Train:", train_df["label"].nunique())
print("Val:", val_df["label"].nunique())
print("Test:", test_df["label"].nunique())





IMG_SIZE = (118, 118)
BATCH_SIZE = 32

# --- Trainingsgenerator (mit Augmentation) ---
train_gen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True
)

# --- Validierungs- & Testgenerator (ohne Augmentation) ---
val_gen = ImageDataGenerator(rescale=1./255)
test_gen = ImageDataGenerator(rescale=1./255)

# --- Generatoren erstellen ---
train_flow = train_gen.flow_from_dataframe(
    train_df,
    x_col="path",
    y_col="label",
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

val_flow = val_gen.flow_from_dataframe(
    val_df,
    x_col="path",
    y_col="label",
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

test_flow = test_gen.flow_from_dataframe(
    test_df,
    x_col="path",
    y_col="label",
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=False  # Test-Set nie mischen
)






model = Sequential([
    Conv2D(16, (3,3), activation='relu', padding="same", input_shape=(118, 118, 3)),
    MaxPooling2D(2,2),

    Conv2D(32, (3,3), activation='relu', padding='same'),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu', padding='same'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(folders), activation='softmax')
])

model.compile(
    optimizer=Adam(learning_rate=0.0005),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)



# --- Training ---
history = model.fit(
    train_flow, 
    epochs=5, 
    validation_data=val_flow, 
    verbose=1
)


# --- Plots ---
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Accuracy während des Trainings')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss während des Trainings')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()



